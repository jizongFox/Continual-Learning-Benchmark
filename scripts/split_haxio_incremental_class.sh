GPUID=$1
OUTDIR=outputs/split_HaxioDataset_incremental_class
REPEAT=1
dataroot=data/version_02
set -e
mkdir -p $OUTDIR
python -u iBatchLearn.py --dataset HaxioDataset  --dataroot=$dataroot  --train_aug --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --force_out_dim 5 --no_class_remap --first_split_size 3 --other_split_size 2 --schedule 10 15 20 --batch_size 16 --model_name resnet18 --model_type resnet2                        --lr 0.001                                  --offline_training  | tee ${OUTDIR}/Offline_Adam_resnet18.log
python -u iBatchLearn.py --dataset HaxioDataset  --dataroot=$dataroot  --train_aug --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --force_out_dim 5 --no_class_remap --first_split_size 3 --other_split_size 2 --schedule 10 15 20 --batch_size 16 --model_name resnet18 --model_type resnet2                                             --lr 0.001                                 | tee ${OUTDIR}/Adam.log
python -u iBatchLearn.py --dataset HaxioDataset  --dataroot=$dataroot  --train_aug --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --force_out_dim 5 --no_class_remap --first_split_size 3 --other_split_size 2 --schedule 10 15 20 --batch_size 16 --model_name resnet18 --model_type resnet2 --agent_type customization  --agent_name EWC        --lr 0.001 --reg_coef 2            | tee ${OUTDIR}/EWC.log
python -u iBatchLearn.py --dataset HaxioDataset  --dataroot=$dataroot  --train_aug --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --force_out_dim 5 --no_class_remap --first_split_size 3 --other_split_size 2 --schedule 10 15 20 --batch_size 16 --model_name resnet18 --model_type resnet2 --agent_type customization  --agent_name EWC_online --lr 0.001 --reg_coef 2            | tee ${OUTDIR}/EWC_online.log
python -u iBatchLearn.py --dataset HaxioDataset  --dataroot=$dataroot  --train_aug --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --force_out_dim 5 --no_class_remap --first_split_size 3 --other_split_size 2 --schedule 10 15 20 --batch_size 16 --model_name resnet18 --model_type resnet2 --agent_type regularization --agent_name SI         --lr 0.001 --reg_coef 0.001        | tee ${OUTDIR}/SI.log
python -u iBatchLearn.py --dataset HaxioDataset  --dataroot=$dataroot  --train_aug --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --force_out_dim 5 --no_class_remap --first_split_size 3 --other_split_size 2 --schedule 10 15 20 --batch_size 16 --model_name resnet18 --model_type resnet2 --agent_type regularization --agent_name L2         --lr 0.001 --reg_coef 500          | tee ${OUTDIR}/L2.log
python -u iBatchLearn.py --dataset HaxioDataset  --dataroot=$dataroot  --train_aug --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --force_out_dim 5 --no_class_remap --first_split_size 3 --other_split_size 2 --schedule 10 15 20 --batch_size 16 --model_name resnet18 --model_type resnet2 --agent_type customization  --agent_name Naive_Rehearsal_1400  --lr 0.001              | tee ${OUTDIR}/Naive_Rehearsal_1400.log
python -u iBatchLearn.py --dataset HaxioDataset  --dataroot=$dataroot  --train_aug --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --force_out_dim 5 --no_class_remap --first_split_size 3 --other_split_size 2 --schedule 10 15 20 --batch_size 16 --model_name resnet18 --model_type resnet2 --agent_type customization  --agent_name Naive_Rehearsal_5600  --lr 0.001              | tee ${OUTDIR}/Naive_Rehearsal_4600.log
python -u iBatchLearn.py --dataset HaxioDataset  --dataroot=$dataroot  --train_aug --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --force_out_dim 5 --no_class_remap --first_split_size 3 --other_split_size 2 --schedule 10 15 20 --batch_size 16 --model_name resnet18 --model_type resnet2 --agent_type regularization --agent_name MAS        --lr 0.001 --reg_coef 0.001        |tee  ${OUTDIR}/MAS.log